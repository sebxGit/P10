{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized dataset:\n",
      "Station_Name                   object\n",
      "Address                        object\n",
      "State_Province                 object\n",
      "End_DateTime           datetime64[ns]\n",
      "Total_Duration        timedelta64[ns]\n",
      "Charging_Time         timedelta64[ns]\n",
      "Energy_Consumption            float64\n",
      "dtype: object\n",
      "Optimized dataset:\n",
      "                                        Station_Name             Address  \\\n",
      "Start_DateTime                                                             \n",
      "2018-01-01 17:49:00  BOULDER / JUNCTION ST1           2280 Junction Pl     \n",
      "2018-01-02 08:52:00  BOULDER / JUNCTION ST1           2280 Junction Pl     \n",
      "2018-01-02 21:11:00  BOULDER / JUNCTION ST1           2280 Junction Pl     \n",
      "2018-01-03 09:19:00  BOULDER / ALPINE ST1             1275 Alpine Ave      \n",
      "2018-01-03 14:13:00  BOULDER / BASELINE ST1           900 Baseline Rd      \n",
      "...                                              ...                 ...   \n",
      "2023-11-30 19:11:00  MUNICIPAL SC / 1100WALNUT1       1100 Walnut          \n",
      "2023-11-30 19:58:00  BOULDER / N BOULDER REC 1        3172 Broadway        \n",
      "2023-11-30 20:01:00  BOULDER / CARPENTER PARK1        1505 30th St         \n",
      "2023-11-30 21:03:00  BOULDER / REC CENTER ST2         1360 Gillaspie Dr    \n",
      "2023-11-30 23:27:00  BOULDER / FACILITIES ST1         1745 14th street     \n",
      "\n",
      "                      State_Province        End_DateTime  Total_Duration  \\\n",
      "Start_DateTime                                                             \n",
      "2018-01-01 17:49:00  Colorado        2018-01-01 19:52:00 0 days 02:03:02   \n",
      "2018-01-02 08:52:00  Colorado        2018-01-02 09:16:00 0 days 00:24:34   \n",
      "2018-01-02 21:11:00  Colorado        2018-01-03 06:23:00 0 days 09:12:21   \n",
      "2018-01-03 09:19:00  Colorado        2018-01-03 11:14:00 0 days 01:54:51   \n",
      "2018-01-03 14:13:00  Colorado        2018-01-03 14:30:00 0 days 00:16:58   \n",
      "...                              ...                 ...             ...   \n",
      "2023-11-30 19:11:00  Colorado        2023-11-30 20:55:00 0 days 01:44:19   \n",
      "2023-11-30 19:58:00  Colorado        2023-11-30 20:10:00 0 days 00:12:13   \n",
      "2023-11-30 20:01:00  Colorado        2023-11-30 20:21:00 0 days 00:19:52   \n",
      "2023-11-30 21:03:00  Colorado        2023-11-30 21:31:00 0 days 00:28:08   \n",
      "2023-11-30 23:27:00  Colorado        2023-12-01 09:02:00 0 days 09:35:17   \n",
      "\n",
      "                      Charging_Time  Energy_Consumption  \n",
      "Start_DateTime                                           \n",
      "2018-01-01 17:49:00 0 days 02:02:44               6.504  \n",
      "2018-01-02 08:52:00 0 days 00:24:19               2.481  \n",
      "2018-01-02 21:11:00 0 days 03:40:52              15.046  \n",
      "2018-01-03 09:19:00 0 days 01:54:29               6.947  \n",
      "2018-01-03 14:13:00 0 days 00:16:44               1.800  \n",
      "...                             ...                 ...  \n",
      "2023-11-30 19:11:00 0 days 01:44:06               5.757  \n",
      "2023-11-30 19:58:00 0 days 00:11:42               1.194  \n",
      "2023-11-30 20:01:00 0 days 00:19:43               1.899  \n",
      "2023-11-30 21:03:00 0 days 00:27:50               1.499  \n",
      "2023-11-30 23:27:00 0 days 03:50:19              17.755  \n",
      "\n",
      "[132021 rows x 7 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart_DateTime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Save the cleaned data to a new CSV file\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleanedColoradoData.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%m/%d/%Y %H:%M\")\n",
    "    except ValueError:\n",
    "        # If that fails, try the ISO8601 format: year-month-day hour:minute:second\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            # Return NaT if both formats fail\n",
    "            print(f\"Could not parse date: {date_str}\")\n",
    "            return pd.NaT\n",
    "\n",
    "\n",
    "# Load the CSV file into a pandas dataframe\n",
    "df = pd.read_csv('ColoradoData.csv')\n",
    "\n",
    "# Strip extra whitespace from the column names\n",
    "df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "# Strip extra whitespace from the date columns\n",
    "df['Start_Date___Time'] = df['Start_Date___Time'].str.strip()\n",
    "df['End_Date___Time'] = df['End_Date___Time'].str.strip()\n",
    "\n",
    "# Now parse the datetime columns using the parse_date function\n",
    "df['Start_DateTime'] = df['Start_Date___Time'].apply(parse_date)\n",
    "df['End_DateTime'] = df['End_Date___Time'].apply(parse_date)\n",
    "\n",
    "# Convert duration columns to timedelta objects\n",
    "df['Total_Duration'] = pd.to_timedelta(df['Total_Duration__hh_mm_ss_'])\n",
    "df['Charging_Time'] = pd.to_timedelta(df['Charging_Time__hh_mm_ss_'])\n",
    "\n",
    "# Convert Energy consumption to a numeric type (handle errors)\n",
    "df['Energy_Consumption'] = pd.to_numeric(df['Energy__kWh_'], errors='coerce')\n",
    "\n",
    "# Remove the columns that are no longer needed\n",
    "df = df.drop(columns=['Start_Date___Time', 'End_Date___Time', 'Total_Duration__hh_mm_ss_',\n",
    "             'Charging_Time__hh_mm_ss_', 'Energy__kWh_', 'ObjectID', 'ObjectId2', 'Start_Time_Zone', 'End_Time_Zone', 'Port_Type', 'GHG_Savings__kg_', 'Gasoline_Savings__gallons_', 'Zip_Postal_Code', 'City'])\n",
    "\n",
    "df.set_index('Start_DateTime', inplace=True)\n",
    "\n",
    "## More data cleaning\n",
    "# Remove rows with negative energy consumption\n",
    "df = df[df['Energy_Consumption'] >= 0]\n",
    "\n",
    "# Remove rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove rows with zero charging time\n",
    "df = df[df['Charging_Time'] > pd.Timedelta(0)]\n",
    "\n",
    "# Remove rows with zero energy consumption\n",
    "df = df[df['Energy_Consumption'] > 0]\n",
    "\n",
    "# Remove rows with zero total duration\n",
    "df = df[df['Total_Duration'] > pd.Timedelta(0)]\n",
    "\n",
    "# Remove rows with total duration less than charging time\n",
    "df = df[df['Total_Duration'] >= df['Charging_Time']]\n",
    "\n",
    "# Verify the conversion by printing the data types\n",
    "print(\"Optimized dataset:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"Optimized dataset:\")\n",
    "print(df)\n",
    "\n",
    "df = df.sort_values(by=['Start_DateTime'], inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('CleanedColoradoData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating (Day, Charging Station, Addresses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'aggregated_energy_consumption', 'daily_sessions',\n",
      "       'avg_charging_time_hours', 'avg_total_duration_hours'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('cleaned_ColoradoData2.csv')\n",
    "\n",
    "# Convert date/time columns to datetime\n",
    "df['Start_DateTime'] = pd.to_datetime(df['Start_DateTime'])\n",
    "df['End_DateTime'] = pd.to_datetime(df['End_DateTime'])\n",
    "\n",
    "# Set Start_DateTime as the index\n",
    "df.set_index('Start_DateTime', inplace=True)\n",
    "\n",
    "# Convert Energy_Consumption to numeric (if not already)\n",
    "df['Energy_Consumption'] = pd.to_numeric(df['Energy_Consumption'])\n",
    "\n",
    "# Convert Charging_Time and Total_Duration from string to timedelta\n",
    "df['Charging_Time'] = pd.to_timedelta(df['Charging_Time'])\n",
    "df['Total_Duration'] = pd.to_timedelta(df['Total_Duration'])\n",
    "\n",
    "df['Charging_Time_sec'] = df['Charging_Time'].dt.total_seconds()\n",
    "df['Total_Duration_sec'] = df['Total_Duration'].dt.total_seconds()\n",
    "\n",
    "\n",
    "# Resample the data by day to aggregate energy consumption, charging time, and total duration\n",
    "daily_df = df.resample('D').agg({\n",
    "    'Energy_Consumption': 'sum',\n",
    "    'Charging_Time_sec': 'mean',\n",
    "    'Total_Duration_sec': 'mean',\n",
    "    'Station_Name': 'count'  # Counting sessions per day\n",
    "}).rename(columns={'Station_Name': 'daily_sessions'})\n",
    "\n",
    "# Count daily sessions using resample size (this counts the number of rows per day)\n",
    "daily_sessions = df.resample('D').size()\n",
    "daily_df['daily_sessions'] = daily_sessions\n",
    "\n",
    "# Rename the columns to match your desired output\n",
    "daily_df.rename(columns={\n",
    "    'Energy_Consumption': 'aggregated_energy_consumption',\n",
    "    'Charging_Time': 'aggregated_average_charging_time',\n",
    "    'Total_Duration': 'aggregated_average_total_duration'\n",
    "}, inplace=True)\n",
    "\n",
    "daily_df['avg_charging_time_hours'] = daily_df['Charging_Time_sec'] / 3600\n",
    "daily_df['avg_total_duration_hours'] = daily_df['Total_Duration_sec'] / 3600\n",
    "\n",
    "# Drop the columns that are no longer needed\n",
    "daily_df = daily_df.drop(columns=['Charging_Time_sec', 'Total_Duration_sec'])\n",
    "\n",
    "# Reset the index to have a 'date' column (renaming the index column from 'Start_DateTime' to 'date')\n",
    "daily_df = daily_df.reset_index().rename(columns={'Start_DateTime': 'date'})\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(daily_df.columns)\n",
    "\n",
    "daily_df = daily_df.drop(columns=['level_0', 'index'], errors='ignore')\n",
    "\n",
    "# Save the aggregated data to a new CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'aggregated_energy_consumption', 'daily_sessions',\n",
      "       'avg_charging_time_hours', 'avg_total_duration_hours',\n",
      "       'avg_energy_per_session', 'CUR', 'TDUR',\n",
      "       'daily_change_in_energy_consumption', 'rolling_avg_energy_consumption',\n",
      "       'rolling_sessions_7d', 'day_of_week', 'is_weekend', 'is_public_holiday',\n",
      "       'rolling_avg_energy_consumption_1d', 'rolling_sessions_1d', 'Day',\n",
      "       'Hour', 'HourSin', 'HourCos'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Energy pr session\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "daily_df['avg_energy_per_session'] = daily_df['aggregated_energy_consumption']/daily_df['daily_sessions']\n",
    "\n",
    "# Charging Utilization Ratio (CUR)\n",
    "daily_df['CUR'] = daily_df['avg_charging_time_hours'] / daily_df['avg_total_duration_hours']\n",
    "\n",
    "# Total Duration Utilization Ratio (TDUR)\n",
    "daily_df['TDUR'] = daily_df['avg_total_duration_hours'] / 24  # 24 hours in a day\n",
    "\n",
    "# Daily Change in Energy Consumption\n",
    "daily_df['daily_change_in_energy_consumption'] = daily_df['aggregated_energy_consumption'].diff()\n",
    "\n",
    "# Rolling Average of Energy Consumption\n",
    "daily_df['rolling_avg_energy_consumption_1d'] = daily_df['aggregated_energy_consumption'].rolling(window=1).mean()\n",
    "daily_df['rolling_sessions_1d'] = daily_df['daily_sessions'].rolling(window=1).mean()\n",
    "\n",
    "# Day of the week and Weekend indicator\n",
    "daily_df['day_of_week'] = daily_df['date'].dt.dayofweek # Monday=0, Sunday=6\n",
    "daily_df['is_weekend'] = daily_df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Public holidays\n",
    "us_holidays = holidays.US()\n",
    "daily_df['is_public_holiday'] = daily_df['date'].dt.date.astype(str).map(us_holidays.get).notnull().astype(int)\n",
    "\n",
    "# Data features\n",
    "daily_df['Day'] = daily_df['date'].dt.day\n",
    "daily_df['Hour'] = daily_df['date'].dt.hour\n",
    "\n",
    "# Cos, Sin transformation of day of the year\n",
    "daily_df['HourSin'] = np.sin(2 * np.pi * daily_df['Hour'] / 24)\n",
    "daily_df['HourCos'] = np.cos(2 * np.pi * daily_df['Hour'] / 24)\n",
    "\n",
    "print(daily_df.columns)\n",
    "\n",
    "# Save the normalized data to a new CSV file\n",
    "daily_df.to_csv('features_ColoradoData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
