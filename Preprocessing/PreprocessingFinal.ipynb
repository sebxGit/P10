{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data to hourly data + adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17544 entries, 2021-11-30 00:00:00 to 2023-11-30 23:00:00\n",
      "Freq: h\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Energy_Consumption          17544 non-null  float64\n",
      " 1   Session_Count               17544 non-null  int64  \n",
      " 2   Day_of_Week                 17544 non-null  int32  \n",
      " 3   Hour_of_Day                 17544 non-null  int32  \n",
      " 4   Month_of_Year               17544 non-null  int32  \n",
      " 5   Year                        17544 non-null  int32  \n",
      " 6   Day/Night                   17544 non-null  bool   \n",
      " 7   IsHoliday                   17544 non-null  int64  \n",
      " 8   Weekend                     17544 non-null  int64  \n",
      " 9   HourSin                     17544 non-null  float64\n",
      " 10  HourCos                     17544 non-null  float64\n",
      " 11  DayOfWeekSin                17544 non-null  float64\n",
      " 12  DayOfWeekCos                17544 non-null  float64\n",
      " 13  MonthOfYearSin              17544 non-null  float64\n",
      " 14  MonthOfYearCos              17544 non-null  float64\n",
      " 15  Season                      17544 non-null  object \n",
      " 16  Energy_Consumption_1h       17543 non-null  float64\n",
      " 17  Energy_Consumption_6h       17538 non-null  float64\n",
      " 18  Energy_Consumption_12h      17532 non-null  float64\n",
      " 19  Energy_Consumption_24h      17520 non-null  float64\n",
      " 20  Energy_Consumption_1w       17376 non-null  float64\n",
      " 21  Energy_Consumption_rolling  17521 non-null  float64\n",
      "dtypes: bool(1), float64(13), int32(4), int64(3), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def convert_to_hourly(data, start_date, end_date):\n",
    "    # Convert date/time columns to datetime\n",
    "    data['Start_DateTime'] = pd.to_datetime(data['Start_DateTime'])\n",
    "    data['End_Time'] = pd.to_datetime(data['End_DateTime'])\n",
    "    data['Charging_Time'] = pd.to_timedelta(data['Charging_Time'])\n",
    "\n",
    "    ####################### FILTER DATASET  #######################\n",
    "\n",
    "    # Take data from 30/11/2021 to 30/11/2023\n",
    "    data = data[(data['Start_DateTime'] >= start_date) & (data['Start_DateTime'] <= end_date)].copy()\n",
    "\n",
    "    # Calculate the end of the charging interval as start time + charging time\n",
    "    data['Charging_EndTime'] = data['Start_DateTime'] + data['Charging_Time']\n",
    "\n",
    "    # Sort the data by the Start_DateTime column\n",
    "    data = data.sort_values(by=['Start_DateTime'], ascending=True)\n",
    "\n",
    "    # Remove duplicates\n",
    "    data = data.drop_duplicates(subset=['Start_DateTime', 'Charging_Time', 'Energy_Consumption'])\n",
    "\n",
    "\n",
    "    ####################### CONVERT DATASET TO HOURLY  #######################\n",
    "\n",
    "    # Split the session into hourly intervals\n",
    "    hourly_rows = []\n",
    "\n",
    "    # Iterate over each row in the dataframe to break charging sessions into hourly intervals\n",
    "    for _, row in data.iterrows():\n",
    "        start, end = row['Start_DateTime'], row['Charging_EndTime']\n",
    "        energy = row['Energy_Consumption']\n",
    "\n",
    "        # Generate hourly intervals\n",
    "        hourly_intervals = pd.date_range(\n",
    "            start=start.floor('h'), end=end.ceil('h'), freq='h')\n",
    "        total_duration = (end - start).total_seconds()\n",
    "\n",
    "        for i in range(len(hourly_intervals) - 1):\n",
    "            interval_start = max(start, hourly_intervals[i])\n",
    "            interval_end = min(end, hourly_intervals[i+1])\n",
    "            interval_duration = (interval_end - interval_start).total_seconds()\n",
    "\n",
    "            energy_fraction = (interval_duration / total_duration) * energy\n",
    "\n",
    "            hourly_rows.append({\n",
    "                'Time': hourly_intervals[i],\n",
    "                'Energy_Consumption': energy_fraction,\n",
    "                \"Session_Count\": 1  # Count of sessions in the interval\n",
    "            })\n",
    "\n",
    "    # Create a new dataframe from the hourly intervals\n",
    "    hourly_df = pd.DataFrame(hourly_rows)\n",
    "\n",
    "    # Aggregate the hourly intervals\n",
    "    hourly_df = hourly_df.groupby('Time').agg({\n",
    "        'Energy_Consumption': 'sum',\n",
    "        'Session_Count': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Convert the Time column to datetime\n",
    "    hourly_df['Time'] = pd.to_datetime(hourly_df['Time'], format=\"%d-%m-%Y %H:%M:%S\")\n",
    "    hourly_df = hourly_df.set_index('Time')\n",
    "\n",
    "    # Define time range for all 24 hours\n",
    "    start_time = hourly_df.index.min().normalize()  # 00:00:00\n",
    "    end_time = hourly_df.index.max().normalize() + pd.Timedelta(days=1) - pd.Timedelta(hours=1)  # 23:00:00\n",
    "\n",
    "    # Change range to time_range_full, so from 00:00:00 to 23:00:00\n",
    "    time_range_full = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "\n",
    "    # Reindex the hourly data to include all hours in the range\n",
    "    hourly_df = hourly_df.reindex(time_range_full, fill_value=0)\n",
    "\n",
    "    # Return the hourly data\n",
    "    return hourly_df\n",
    "\n",
    "def add_features(hourly_df, start_date, end_date):\n",
    "  ####################### TIMED BASED FEATURES  #######################\n",
    "  hourly_df['Day_of_Week'] = hourly_df.index.dayofweek\n",
    "\n",
    "  # Add hour of the day\n",
    "  hourly_df['Hour_of_Day'] = hourly_df.index.hour\n",
    "\n",
    "  # Add month of the year\n",
    "  hourly_df['Month_of_Year'] = hourly_df.index.month\n",
    "\n",
    "  # Add year\n",
    "  hourly_df['Year'] = hourly_df.index.year\n",
    "\n",
    "  # Add day/night\n",
    "  hourly_df['Day/Night'] = (hourly_df['Hour_of_Day']\n",
    "                            >= 6) & (hourly_df['Hour_of_Day'] <= 18)\n",
    "\n",
    "  # Add holiday\n",
    "  us_holidays = holidays.US(years=range(start_date.year, end_date.year + 1))\n",
    "  hourly_df['IsHoliday'] = hourly_df.index.map(\n",
    "      lambda x: 1 if x.date() in us_holidays else 0)\n",
    "\n",
    "  # Add weekend\n",
    "  hourly_df['Weekend'] = (hourly_df['Day_of_Week'] >= 5).astype(int)\n",
    "\n",
    "  ####################### CYCLIC FEATURES  #######################\n",
    "  # Cos and sin transformations for cyclic features (hour of the day, day of the week, month of the year)\n",
    "\n",
    "  hourly_df['HourSin'] = np.sin(2 * np.pi * hourly_df['Hour_of_Day'] / 24)\n",
    "  hourly_df['HourCos'] = np.cos(2 * np.pi * hourly_df['Hour_of_Day'] / 24)\n",
    "  hourly_df['DayOfWeekSin'] = np.sin(2 * np.pi * hourly_df['Day_of_Week'] / 7)\n",
    "  hourly_df['DayOfWeekCos'] = np.cos(2 * np.pi * hourly_df['Day_of_Week'] / 7)\n",
    "  hourly_df['MonthOfYearSin'] = np.sin(\n",
    "      2 * np.pi * hourly_df['Month_of_Year'] / 12)\n",
    "  hourly_df['MonthOfYearCos'] = np.cos(\n",
    "      2 * np.pi * hourly_df['Month_of_Year'] / 12)\n",
    "\n",
    "  ####################### SEASONAL FEATURES  #######################\n",
    "  month_to_season = {1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring', 6: 'Summer',\n",
    "                     7: 'Summer', 8: 'Summer', 9: 'Autumn', 10: 'Autumn', 11: 'Autumn', 12: 'Winter'}\n",
    "  hourly_df['Season'] = hourly_df['Month_of_Year'].map(month_to_season)\n",
    "\n",
    "  ####################### HISTORICAL CONSUMPTION FEATURES  #######################\n",
    "  # Lag features\n",
    "  # 1h\n",
    "  hourly_df['Energy_Consumption_1h'] = hourly_df['Energy_Consumption'].shift(1)\n",
    "\n",
    "  # 6h\n",
    "  hourly_df['Energy_Consumption_6h'] = hourly_df['Energy_Consumption'].shift(6)\n",
    "\n",
    "  # 12h\n",
    "  hourly_df['Energy_Consumption_12h'] = hourly_df['Energy_Consumption'].shift(12)\n",
    "\n",
    "  # 24h\n",
    "  hourly_df['Energy_Consumption_24h'] = hourly_df['Energy_Consumption'].shift(24)\n",
    "\n",
    "  # 1 week\n",
    "  hourly_df['Energy_Consumption_1w'] = hourly_df['Energy_Consumption'].shift(24*7)\n",
    "\n",
    "  # Rolling average\n",
    "  # 24h\n",
    "  hourly_df['Energy_Consumption_rolling'] = hourly_df['Energy_Consumption'].rolling(window=24).mean()\n",
    "\n",
    "  return hourly_df\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.to_datetime('2021-11-30')\n",
    "end_date = pd.to_datetime('2023-11-30')\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('TestDataset/CleanedColoradoData.csv')\n",
    "\n",
    "# Convert to hourly data\n",
    "hourly_df = convert_to_hourly(data=data, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Add features\n",
    "hourly_df = add_features(hourly_df, start_date, end_date)\n",
    "\n",
    "print(hourly_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Cleaned Dataset\n",
    "### Already Done, see 'TestDataset/CleanedColoradoData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date_str):\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%m/%d/%Y %H:%M\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date: {date_str}\")\n",
    "            return pd.NaT\n",
    "\n",
    "def clean_data():\n",
    "    # Load the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv('ColoradoData.csv')\n",
    "\n",
    "    # Strip extra whitespace from the column names\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "    # Strip extra whitespace from the date columns\n",
    "    df['Start_Date___Time'] = df['Start_Date___Time'].str.strip()\n",
    "    df['End_Date___Time'] = df['End_Date___Time'].str.strip()\n",
    "\n",
    "    # Now parse the datetime columns using the parse_date function\n",
    "    df['Start_DateTime'] = df['Start_Date___Time'].apply(parse_date)\n",
    "    df['End_DateTime'] = df['End_Date___Time'].apply(parse_date)\n",
    "\n",
    "    # Convert duration columns to timedelta objects\n",
    "    df['Total_Duration'] = pd.to_timedelta(df['Total_Duration__hh_mm_ss_'])\n",
    "    df['Charging_Time'] = pd.to_timedelta(df['Charging_Time__hh_mm_ss_'])\n",
    "\n",
    "    # Convert Energy consumption to a numeric type (handle errors)\n",
    "    df['Energy_Consumption'] = pd.to_numeric(\n",
    "        df['Energy__kWh_'], errors='coerce')\n",
    "\n",
    "    # Remove the columns that are no longer needed\n",
    "    df = df.drop(columns=['Start_Date___Time', 'End_Date___Time', 'Total_Duration__hh_mm_ss_',\n",
    "                          'Charging_Time__hh_mm_ss_', 'Energy__kWh_', 'ObjectID', 'ObjectId2', 'Start_Time_Zone', 'End_Time_Zone', 'Port_Type', 'GHG_Savings__kg_', 'Gasoline_Savings__gallons_', 'Zip_Postal_Code', 'City'])\n",
    "\n",
    "    # More data cleaning\n",
    "    # Remove rows with negative energy consumption\n",
    "    df = df[df['Energy_Consumption'] >= 0]\n",
    "\n",
    "    # Remove rows with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Remove rows with zero charging time\n",
    "    df = df[df['Charging_Time'] > pd.Timedelta(0)]\n",
    "\n",
    "    # Remove rows with zero energy consumption\n",
    "    df = df[df['Energy_Consumption'] > 0]\n",
    "\n",
    "    # Remove rows with zero total duration\n",
    "    df = df[df['Total_Duration'] > pd.Timedelta(0)]\n",
    "\n",
    "    # Remove rows with total duration less than charging time\n",
    "    df = df[df['Total_Duration'] >= df['Charging_Time']]\n",
    "\n",
    "    # Sort the data by the Start_DateTime column\n",
    "    df = df.sort_values(by=['Start_DateTime'], ascending=True)\n",
    "\n",
    "    # Save the cleaned data to a new CSV file\n",
    "    df.to_csv('TestDataset/CleanedColoradoData.csv')\n",
    "\n",
    "    return df\n",
    "\n",
    "df = clean_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
