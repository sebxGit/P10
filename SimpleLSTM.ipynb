{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM with Colorado Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.dates as mdates\n",
    "import pytorch_lightning as pl\n",
    "import holidays\n",
    "\n",
    "# Check if GPU or MPS is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print (f\"Using device: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Colorado Data (Convert + Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17544 entries, 2021-11-30 00:00:00 to 2023-11-30 23:00:00\n",
      "Freq: h\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Energy_Consumption          17544 non-null  float64\n",
      " 1   Session_Count               17544 non-null  int64  \n",
      " 2   Day_of_Week                 17544 non-null  int32  \n",
      " 3   Hour_of_Day                 17544 non-null  int32  \n",
      " 4   Month_of_Year               17544 non-null  int32  \n",
      " 5   Year                        17544 non-null  int32  \n",
      " 6   Day/Night                   17544 non-null  bool   \n",
      " 7   IsHoliday                   17544 non-null  int64  \n",
      " 8   Weekend                     17544 non-null  int64  \n",
      " 9   HourSin                     17544 non-null  float64\n",
      " 10  HourCos                     17544 non-null  float64\n",
      " 11  DayOfWeekSin                17544 non-null  float64\n",
      " 12  DayOfWeekCos                17544 non-null  float64\n",
      " 13  MonthOfYearSin              17544 non-null  float64\n",
      " 14  MonthOfYearCos              17544 non-null  float64\n",
      " 15  Season                      17544 non-null  object \n",
      " 16  Energy_Consumption_1h       17543 non-null  float64\n",
      " 17  Energy_Consumption_6h       17538 non-null  float64\n",
      " 18  Energy_Consumption_12h      17532 non-null  float64\n",
      " 19  Energy_Consumption_24h      17520 non-null  float64\n",
      " 20  Energy_Consumption_1w       17376 non-null  float64\n",
      " 21  Energy_Consumption_rolling  17521 non-null  float64\n",
      "dtypes: bool(1), float64(13), int32(4), int64(3), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def convert_to_hourly(data, start_date, end_date):\n",
    "    # Convert date/time columns to datetime\n",
    "    data['Start_DateTime'] = pd.to_datetime(data['Start_DateTime'])\n",
    "    data['End_Time'] = pd.to_datetime(data['End_DateTime'])\n",
    "    data['Charging_Time'] = pd.to_timedelta(data['Charging_Time'])\n",
    "\n",
    "    ####################### FILTER DATASET  #######################\n",
    "\n",
    "    # Take data from 30/11/2021 to 30/11/2023\n",
    "    data = data[(data['Start_DateTime'] >= start_date) & (data['Start_DateTime'] <= end_date)].copy()\n",
    "\n",
    "    # Calculate the end of the charging interval as start time + charging time\n",
    "    data['Charging_EndTime'] = data['Start_DateTime'] + data['Charging_Time']\n",
    "\n",
    "    # Sort the data by the Start_DateTime column\n",
    "    data = data.sort_values(by=['Start_DateTime'], ascending=True)\n",
    "\n",
    "    # Remove duplicates\n",
    "    data = data.drop_duplicates(subset=['Start_DateTime', 'Charging_Time', 'Energy_Consumption'])\n",
    "\n",
    "\n",
    "    ####################### CONVERT DATASET TO HOURLY  #######################\n",
    "\n",
    "    # Split the session into hourly intervals\n",
    "    hourly_rows = []\n",
    "\n",
    "    # Iterate over each row in the dataframe to break charging sessions into hourly intervals\n",
    "    for _, row in data.iterrows():\n",
    "        start, end = row['Start_DateTime'], row['Charging_EndTime']\n",
    "        energy = row['Energy_Consumption']\n",
    "\n",
    "        # Generate hourly intervals\n",
    "        hourly_intervals = pd.date_range(\n",
    "            start=start.floor('h'), end=end.ceil('h'), freq='h')\n",
    "        total_duration = (end - start).total_seconds()\n",
    "\n",
    "        for i in range(len(hourly_intervals) - 1):\n",
    "            interval_start = max(start, hourly_intervals[i])\n",
    "            interval_end = min(end, hourly_intervals[i+1])\n",
    "            interval_duration = (interval_end - interval_start).total_seconds()\n",
    "\n",
    "            energy_fraction = (interval_duration / total_duration) * energy\n",
    "\n",
    "            hourly_rows.append({\n",
    "                'Time': hourly_intervals[i],\n",
    "                'Energy_Consumption': energy_fraction,\n",
    "                \"Session_Count\": 1  # Count of sessions in the interval\n",
    "            })\n",
    "\n",
    "    # Create a new dataframe from the hourly intervals\n",
    "    hourly_df = pd.DataFrame(hourly_rows)\n",
    "\n",
    "    # Aggregate the hourly intervals\n",
    "    hourly_df = hourly_df.groupby('Time').agg({\n",
    "        'Energy_Consumption': 'sum',\n",
    "        'Session_Count': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Convert the Time column to datetime\n",
    "    hourly_df['Time'] = pd.to_datetime(hourly_df['Time'], format=\"%d-%m-%Y %H:%M:%S\")\n",
    "    hourly_df = hourly_df.set_index('Time')\n",
    "\n",
    "    # Define time range for all 24 hours\n",
    "    start_time = hourly_df.index.min().normalize()  # 00:00:00\n",
    "    end_time = hourly_df.index.max().normalize() + pd.Timedelta(days=1) - pd.Timedelta(hours=1)  # 23:00:00\n",
    "\n",
    "    # Change range to time_range_full, so from 00:00:00 to 23:00:00\n",
    "    time_range_full = pd.date_range(start=start_time, end=end_time, freq='h')\n",
    "\n",
    "    # Reindex the hourly data to include all hours in the range\n",
    "    hourly_df = hourly_df.reindex(time_range_full, fill_value=0)\n",
    "\n",
    "    # Return the hourly data\n",
    "    return hourly_df\n",
    "\n",
    "def add_features(hourly_df, start_date, end_date):\n",
    "  ####################### TIMED BASED FEATURES  #######################\n",
    "  hourly_df['Day_of_Week'] = hourly_df.index.dayofweek\n",
    "\n",
    "  # Add hour of the day\n",
    "  hourly_df['Hour_of_Day'] = hourly_df.index.hour\n",
    "\n",
    "  # Add month of the year\n",
    "  hourly_df['Month_of_Year'] = hourly_df.index.month\n",
    "\n",
    "  # Add year\n",
    "  hourly_df['Year'] = hourly_df.index.year\n",
    "\n",
    "  # Add day/night\n",
    "  hourly_df['Day/Night'] = (hourly_df['Hour_of_Day']\n",
    "                            >= 6) & (hourly_df['Hour_of_Day'] <= 18)\n",
    "\n",
    "  # Add holiday\n",
    "  us_holidays = holidays.US(years=range(start_date.year, end_date.year + 1))\n",
    "  hourly_df['IsHoliday'] = hourly_df.index.map(lambda x: 1 if x.date() in us_holidays else 0)\n",
    "\n",
    "  # Add weekend\n",
    "  hourly_df['Weekend'] = (hourly_df['Day_of_Week'] >= 5).astype(int)\n",
    "\n",
    "  ####################### CYCLIC FEATURES  #######################\n",
    "  # Cos and sin transformations for cyclic features (hour of the day, day of the week, month of the year)\n",
    "\n",
    "  hourly_df['HourSin'] = np.sin(2 * np.pi * hourly_df['Hour_of_Day'] / 24)\n",
    "  hourly_df['HourCos'] = np.cos(2 * np.pi * hourly_df['Hour_of_Day'] / 24)\n",
    "  hourly_df['DayOfWeekSin'] = np.sin(2 * np.pi * hourly_df['Day_of_Week'] / 7)\n",
    "  hourly_df['DayOfWeekCos'] = np.cos(2 * np.pi * hourly_df['Day_of_Week'] / 7)\n",
    "  hourly_df['MonthOfYearSin'] = np.sin(2 * np.pi * hourly_df['Month_of_Year'] / 12)\n",
    "  hourly_df['MonthOfYearCos'] = np.cos(2 * np.pi * hourly_df['Month_of_Year'] / 12)\n",
    "\n",
    "  ####################### SEASONAL FEATURES  #######################\n",
    "  month_to_season = {1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring', 6: 'Summer',\n",
    "                     7: 'Summer', 8: 'Summer', 9: 'Autumn', 10: 'Autumn', 11: 'Autumn', 12: 'Winter'}\n",
    "  hourly_df['Season'] = hourly_df['Month_of_Year'].map(month_to_season)\n",
    "\n",
    "  ####################### HISTORICAL CONSUMPTION FEATURES  #######################\n",
    "  # Lag features\n",
    "  # 1h\n",
    "  hourly_df['Energy_Consumption_1h'] = hourly_df['Energy_Consumption'].shift(1)\n",
    "\n",
    "  # 6h\n",
    "  hourly_df['Energy_Consumption_6h'] = hourly_df['Energy_Consumption'].shift(6)\n",
    "\n",
    "  # 12h\n",
    "  hourly_df['Energy_Consumption_12h'] = hourly_df['Energy_Consumption'].shift(12)\n",
    "\n",
    "  # 24h\n",
    "  hourly_df['Energy_Consumption_24h'] = hourly_df['Energy_Consumption'].shift(24)\n",
    "\n",
    "  # 1 week\n",
    "  hourly_df['Energy_Consumption_1w'] = hourly_df['Energy_Consumption'].shift(24*7)\n",
    "\n",
    "  # Rolling average\n",
    "  # 24h\n",
    "  hourly_df['Energy_Consumption_rolling'] = hourly_df['Energy_Consumption'].rolling(window=24).mean()\n",
    "\n",
    "  return hourly_df\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = pd.to_datetime('2021-11-30')\n",
    "end_date = pd.to_datetime('2023-11-30')\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Colorado/Preprocessing/TestDataset/CleanedColoradoData.csv')\n",
    "\n",
    "# Convert to hourly data\n",
    "hourly_df = convert_to_hourly(data=data, start_date=start_date, end_date=end_date)\n",
    "\n",
    "# Add features\n",
    "hourly_df = add_features(hourly_df, start_date, end_date)\n",
    "\n",
    "print(hourly_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Dataset and Creating Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m features = [\u001b[33m'\u001b[39m\u001b[33mSession_Count\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHourSin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mHourCos\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDayOfWeekSin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDayOfWeekCos\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      3\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mMonthOfYearSin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMonthOfYearCos\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mIsHoliday\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWeekend\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mEnergy_Consumption_1h\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEnergy_Consumption_6h\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEnergy_Consumption_12h\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mEnergy_Consumption_24h\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m target = \u001b[33m'\u001b[39m\u001b[33mEnergy_Consumption\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m hourly_df = scaler.fit_transform(\u001b[43mhourly_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Convert the numpy array to a PyTorch tensor\u001b[39;00m\n\u001b[32m     11\u001b[39m hourly_tensor = torch.tensor(hourly_df, dtype=torch.float32)\n",
      "\u001b[31mIndexError\u001b[39m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "features = ['Session_Count', 'HourSin', 'HourCos', 'DayOfWeekSin', 'DayOfWeekCos',\n",
    "            'MonthOfYearSin', 'MonthOfYearCos', 'IsHoliday', 'Weekend',\n",
    "            'Energy_Consumption_1h', 'Energy_Consumption_6h', 'Energy_Consumption_12h',\n",
    "            'Energy_Consumption_24h']\n",
    "target = 'Energy_Consumption'\n",
    "\n",
    "hourly_df = scaler.fit_transform(hourly_df[features + [target]])\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "hourly_tensor = torch.tensor(hourly_df, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sequences, Split dataset and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m seq_length = \u001b[32m24\u001b[39m\n\u001b[32m     11\u001b[39m target_idx = target\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m X, y = \u001b[43mcreate_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhourly_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcreate_sequences\u001b[39m\u001b[34m(data, target_idx, seq_length)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data) - seq_length):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Append all the features except target\u001b[39;00m\n\u001b[32m      5\u001b[39m     X.append(data[i:i+seq_length, :-\u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     y.append(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Target feature\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack(X), torch.tensor(y)\n",
      "\u001b[31mTypeError\u001b[39m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "def create_sequences(data, target_idx, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Append all the features except target\n",
    "        X.append(data[i:i+seq_length, :-1])\n",
    "        y.append(data[i+seq_length, target_idx])  # Target feature\n",
    "    return torch.stack(X), torch.tensor(y)\n",
    "\n",
    "# Number of past hours used for prediction\n",
    "seq_length = 24\n",
    "target_idx = target\n",
    "X, y = create_sequences(hourly_tensor, target_idx=target_idx, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size), torch.zeros(1, 1, self.hidden_layer_size))\n",
    "        self.name = \"LSTM\"\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(\n",
    "            input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
