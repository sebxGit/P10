{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import DeviceStatsMonitor\n",
    "from lightning.pytorch.callbacks import BasePredictionWriter\n",
    "from lightning.pytorch.profilers import PyTorchProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "  def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 1):\n",
    "    self.X = torch.tensor(X).float()\n",
    "    self.y = torch.tensor(y).float()\n",
    "    self.seq_len = seq_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.X.__len__() - (self.seq_len-1)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColoradoDataModule(L.LightningDataModule):\n",
    "  def __init__(self, data_dir: str, scaler: int, seq_len: int, batch_size: int, num_workers: int, is_persistent: bool):\n",
    "    super().__init__()\n",
    "    self.data_dir = data_dir\n",
    "    self.scaler = scaler\n",
    "    self.seq_len = seq_len\n",
    "    self.batch_size = batch_size\n",
    "    self.num_workers = num_workers\n",
    "    self.is_persistent = is_persistent\n",
    "    self.X_train = None\n",
    "    self.y_train = None\n",
    "    self.X_val = None\n",
    "    self.y_val = None\n",
    "    self.X_test = None\n",
    "    self.y_test = None\n",
    "\n",
    "  def setup(self, stage: str):\n",
    "    df = pd.read_csv(self.data_dir)\n",
    "    df.index = df['Start_DateTime']\n",
    "    df = df[['Start_DateTime', 'Energy_Consumption']].sort_index()\n",
    "    df.dropna(inplace=True)\n",
    "    df['Start_DateTime'] = pd.to_datetime(df['Start_DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df.set_index('Start_DateTime', inplace=True)\n",
    "    X = df.copy()\n",
    "    y = X['Energy_Consumption'].shift(-1).ffill()\n",
    "    X_tv, self.X_test, y_tv, self.y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X_tv, y_tv, test_size=0.25, shuffle=False)\n",
    "    \n",
    "    preprocessing = self.scaler\n",
    "    preprocessing.fit(self.X_train) # should only fit to training data\n",
    "        \n",
    "    if stage == \"fit\" or stage is None:\n",
    "      self.X_train = preprocessing.transform(self.X_train)\n",
    "      self.y_train = self.y_train.values.reshape((-1, 1))\n",
    "      self.X_val = preprocessing.transform(self.X_val)\n",
    "      self.y_val = self.y_val.values.reshape((-1, 1))\n",
    "\n",
    "    if stage == \"test\" or \"predict\" or stage is None:\n",
    "      self.X_test = preprocessing.transform(self.X_test)\n",
    "      self.y_test = self.y_test.values.reshape((-1, 1))\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    train_dataset = TimeSeriesDataset(self.X_train, self.y_train, seq_len=self.seq_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=self.is_persistent)\n",
    "    return train_loader\n",
    "  \n",
    "  def val_dataloader(self):\n",
    "    val_dataset = TimeSeriesDataset(self.X_val, self.y_val, seq_len=self.seq_len)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=self.is_persistent)\n",
    "    return val_loader\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    test_dataset = TimeSeriesDataset(self.X_test, self.y_test, seq_len=self.seq_len)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=self.is_persistent)\n",
    "    return test_loader\n",
    "\n",
    "  def predict_dataloader(self):\n",
    "    test_dataset = TimeSeriesDataset(self.X_test, self.y_test, seq_len=self.seq_len)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=self.is_persistent)\n",
    "    return test_loader\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "  def __init__(self, input_size, hidden_size, num_layers, criterion, dropout, learning_rate):\n",
    "    super().__init__()\n",
    "    self.save_hyperparameters(ignore=['criterion'])\n",
    "    self.dropout = dropout\n",
    "    self.criterion = criterion\n",
    "    self.learning_rate = learning_rate\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out, _ = self.lstm(x)\n",
    "    out = self.fc(out[:, -1, :])  # Get the last time step\n",
    "    return out\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self(x)\n",
    "    train_loss = self.criterion(y_hat, y) \n",
    "    self.log(\"train_loss\", train_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return train_loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self(x)\n",
    "    val_loss = self.criterion(y_hat, y)\n",
    "    self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return val_loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self(x)\n",
    "    test_loss = self.criterion(y_hat, y)\n",
    "    self.log(\"test_loss\", test_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return test_loss\n",
    "\n",
    "  def predict_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat = self(x)\n",
    "    return y_hat\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWriter(BasePredictionWriter):\n",
    "  def __init__(self, output_dir, write_interval):\n",
    "    super().__init__(write_interval)\n",
    "    self.output_dir = output_dir\n",
    "\n",
    "  def write_on_epoch_end(self, trainer, pl_module, predictions, batch_indices):\n",
    "    torch.save(predictions, os.path.join(self.output_dir, f\"predictions_{trainer.global_rank}.pt\"))\n",
    "    # torch.save(batch_indices, os.path.join(self.output_dir, f\"batch_indices_{trainer.global_rank}.pt\")) # for batch indices if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "  seq_len = 12,\n",
    "  batch_size = 8,\n",
    "  criterion = nn.MSELoss(),\n",
    "  max_epochs = 50,\n",
    "  n_features = 7,\n",
    "  hidden_size = 100,\n",
    "  num_layers = 1,\n",
    "  dropout = 1, # can be 0.2 if more output layers are present\n",
    "  learning_rate = 0.001,\n",
    "  num_workers = 0, # only work in .py for me\n",
    "  is_persistent = False, # only work in .py for me\n",
    "  scaler = MinMaxScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size=1, hidden_size=params['hidden_size'], num_layers=params['num_layers'], criterion=params['criterion'], dropout=params['dropout'], learning_rate=params['learning_rate'])\n",
    "colmod = ColoradoDataModule(data_dir='ColoradoData_Boulder.csv', scaler=params['scaler'], seq_len=params['seq_len'], batch_size=params['batch_size'], num_workers=params['num_workers'], is_persistent=params['is_persistent'])\n",
    "pred_writer = CustomWriter(output_dir=\"Models\", write_interval=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottleneck Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_bottleneck = L.Trainer(max_epochs=50, profiler=\"simple\")\n",
    "trainer_bottleneck.fit(model, colmod)\n",
    "trainer_bottleneck.test(model, colmod)\n",
    "trainer_bottleneck.predict(model, colmod, return_predictions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_cpu = L.Trainer(profiler=PyTorchProfiler())\n",
    "trainer_cpu.fit(model, colmod)\n",
    "trainer_cpu.test(model, colmod)\n",
    "trainer_cpu.predict(model, colmod, return_predictions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_eval = L.Trainer(max_epochs=50, callbacks=[DeviceStatsMonitor()])\n",
    "trainer_eval.fit(model, colmod)\n",
    "trainer_eval.test(model, colmod)\n",
    "trainer_eval.predict(model, colmod, return_predictions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Development run (runs n batches of training, validation and test to check for bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_dev = L.Trainer(max_epochs=params['max_epochs'], default_root_dir='Models', callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")], fast_dev_run=10)\n",
    "trainer_dev.fit(model, colmod)\n",
    "trainer_dev.test(model, colmod)\n",
    "trainer_dev.predict(model, colmod, return_predictions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find largest batch size fitting into memory, often yielding better estimations of gradients but can result in longer runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_tun = L.Trainer(max_epochs=params['max_epochs'], default_root_dir='Models', callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "tuner = Tuner(trainer_tun)\n",
    "\n",
    "tuner.scale_batch_size(model, colmod, mode=\"power\")\n",
    "# tuner.scale_batch_size(model, colmod, mode=\"binsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Learning Rate Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_LRtun = L.Trainer(max_epochs=params['max_epochs'], default_root_dir='Models', callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\")])\n",
    "tuner2 = Tuner(trainer_LRtun)\n",
    "\n",
    "lr_finder = tuner2.lr_find(model, colmod)\n",
    "# print(lr_finder.results)\n",
    "\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "new_lr = lr_finder.suggestion()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
