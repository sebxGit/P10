{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.dates as mdates\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers.csv_logs import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, train_window):\n",
    "        self.data = data\n",
    "        self.sequences = self.create_inout_sequences(data, train_window)\n",
    "\n",
    "    def create_inout_sequences(self, input_data, tw):\n",
    "        inout_seq = []\n",
    "        L = len(input_data)\n",
    "        for i in range(L-tw):\n",
    "            train_seq = input_data[i:i+tw]\n",
    "            train_label = input_data[i+tw:i+tw+1]\n",
    "            inout_seq.append((train_seq, train_label))\n",
    "        return inout_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColoradoDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, seq_len = 1, batch_size = 128, num_workers=0):\n",
    "    super().__init__()\n",
    "    self.seq_len = seq_len\n",
    "    self.batch_size = batch_size\n",
    "    self.num_workers = num_workers\n",
    "    self.train = None\n",
    "    self.val = None\n",
    "    self.test = None\n",
    "    self.columns = None\n",
    "    self.preprocessing = None\n",
    "\n",
    "  def prepare_data(self):\n",
    "    pass\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    if stage == 'fit' and self.train is not None:\n",
    "      return \n",
    "    if stage == 'test' and self.test is not None:\n",
    "      return\n",
    "    if stage is None and self.train is not None and self.test is not None:  \n",
    "      return\n",
    "\n",
    "    # add colorado data preprocessing instead\n",
    "    df = pd.read_csv('ColoradoData_Boulder.csv')\n",
    "    df.index = df['Start_DateTime']\n",
    "    df = df[['Start_DateTime', 'Energy_Consumption']].sort_index()\n",
    "    df.dropna(inplace=True)\n",
    "    df['Start_DateTime'] = pd.to_datetime(df['Start_DateTime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df.set_index('Start_DateTime', inplace=True)\n",
    "\n",
    "    # splitting data into train, val, test\n",
    "    train_size = int(0.6 * len(df))\n",
    "    validation_size = int(0.2 * len(df))\n",
    "    test_size = int(0.2 * len(df))\n",
    "\n",
    "    all_data = df['Energy_Consumption'].values.astype(float)\n",
    "\n",
    "    train_set = all_data[:train_size]\n",
    "    validation_set = all_data[train_size:train_size + validation_size]\n",
    "    test_set = all_data[train_size + validation_size:]\n",
    "\n",
    "    # scaling the data splits\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    if stage == 'fit' or stage is None:\n",
    "      train_data_normalized = scaler.fit_transform(train_set.reshape(-1, 1))\n",
    "      validation_data_normalized = scaler.fit_transform(validation_set.reshape(-1, 1))\n",
    "      self.train = torch.FloatTensor(train_data_normalized).view(-1)\n",
    "      self.val = torch.FloatTensor(validation_data_normalized).view(-1)\n",
    "\n",
    "    if stage == 'test' or stage is None:\n",
    "      test_data_normalized = scaler.fit_transform(test_set.reshape(-1, 1))\n",
    "      self.test = torch.FloatTensor(test_data_normalized).view(-1)\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    train_dataset = TimeSeriesDataset(self.train, self.seq_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    return train_loader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    val_dataset = TimeSeriesDataset(self.val, self.seq_len)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    return val_loader\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    test_dataset = TimeSeriesDataset(self.test, self.seq_len)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    return test_loader   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self, input_size=1, hidden_layer_size=100, output_size=1, n_features, \n",
    "                seq_len, batch_size, num_layers, dropout, learning_rate, criterion):\n",
    "    super().__init__()\n",
    "    self.seq_len = seq_len\n",
    "    self.batch_size = batch_size\n",
    "    self.num_layers = num_layers\n",
    "    self.dropout = dropout\n",
    "    self.criterion = criterion\n",
    "    self.learning_rate = learning_rate\n",
    "    self.hidden_layer_size = hidden_layer_size\n",
    "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "    self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "    self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size), torch.zeros(1,1,self.hidden_layer_size))\n",
    "    self.name = \"LSTM\"\n",
    "\n",
    "  def forward(self, input_seq):\n",
    "    lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "    predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "    return predictions[-1]\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    pass\n",
    "    #https://www.kaggle.com/code/tartakovsky/pytorch-lightning-lstm-timeseries-clean-code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
