{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM, Informer, NHITS, DLinear\n",
    "from neuralforecast.losses.pytorch import RMSE\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "from pytorch_forecasting import MAE\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n",
    "\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "\n",
    "def data_preprocessing():\n",
    "    return \n",
    "\n",
    "def sample_data(date_start, date_end, data_split, n_observations=None):\n",
    "\t\tdf = data_preprocessing()\n",
    "    date_start = datetime.strptime(date_start, '%Y-%m-%d')\n",
    "    date_end = datetime.strptime(date_end, '%Y-%m-%d') + timedelta(hours=24)\n",
    "\t\tfiltered_df = df[(df.index >= date_start) & (df.index <= date_end)]\n",
    "\n",
    "\t\tif n_observations is not None:\n",
    "\t\t\t\tfiltered_df = filtered_df.head(n_observations)\n",
    "\n",
    "\t\treturn np.split(df.sample(frac=1, random_state=42), [int(data_split[0] * len(df)), train_end + int(data_split[1] * len(df))])\n",
    "\n",
    "def save_tuning(model_name, trial):\n",
    "\ttry:\n",
    "\t\tdf_tuning = pd.read_csv('tuning.csv')\n",
    "\texcept:\n",
    "\t\tdf_tuning = pd.DataFrame(columns=['model', 'accuracy', 'params'])\n",
    "\n",
    "\tnew_row = {'model': model_name, 'accuracy': trial.value, 'params': str(trial.params)}\n",
    "\tnew_row_df = pd.DataFrame([new_row]).dropna(axis=1, how='all')\n",
    "\tdf_tuning = pd.concat([df_tuning, new_row_df], ignore_index=True)\n",
    "\tdf_tuning = df_tuning.sort_values(by=['model', 'accuracy', 'params'], ascending=True).reset_index(drop=True)\n",
    "\tdf_tuning.to_csv('tuning.csv', index=False)\n",
    "\n",
    "def objective_LSTM(trial, data_train, data_test, forecast_horizon):\n",
    "    nf = NeuralForecast(\n",
    "        models=[LSTM(h=forecast_horizon, input_size=-1, loss=RMSE(),\n",
    "                     encoder_n_layers=trial.suggest_categorical(\n",
    "                         'encoder_n_layers', [1, 2, 5, 10]),\n",
    "                     encoder_hidden_size=trial.suggest_categorical(\n",
    "                         'encoder_hidden_size', [100, 200, 300, 400]),\n",
    "                     context_size=trial.suggest_categorical(\n",
    "                         'context_size', [5, 10, 15, 20]),\n",
    "                     decoder_hidden_size=trial.suggest_categorical(\n",
    "                         'decoder_hidden_size', [100, 200, 300, 400]),\n",
    "                     decoder_layers=trial.suggest_categorical(\n",
    "                         'decoder_layers', [1, 2, 5, 10]),\n",
    "                     max_steps=trial.suggest_categorical(\n",
    "                         'max_steps', [200, 500, 1000, 3000]),\n",
    "                     val_check_steps=trial.suggest_categorical(\n",
    "                         'val_check_steps', [10, 20, 50, 100, 250, 500]),\n",
    "                     batch_size=trial.suggest_categorical(\n",
    "                         'batch_size', [16, 32, 64, 128]),\n",
    "                     scaler_type=trial.suggest_categorical(\n",
    "                         'scaler_type', ['standard', 'minmax', 'robust']),\n",
    "                     )\n",
    "                ],\n",
    "        freq='H'\n",
    "    )\n",
    "    nf.fit(data_train)\n",
    "    predictions = nf.predict(data_test)\n",
    "    return root_mean_squared_error(data_test['y'], predictions['LSTM'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t\t# constant in tunings\n",
    "    trials = 100\n",
    "    date_start = '2023-11-01'\n",
    "    date_end = '2024-11-01'\n",
    "\n",
    "    # configurable variables\n",
    "\t\tmodel_name = 'LSTM'\n",
    "\t\tn_observations = None # Specify number of observations in dataset, otherwise None\n",
    "\t\tforecast_horizon = 30\n",
    "\n",
    "    # constant sampling\n",
    "    data_split = [.6, .2, .2] # 60% train, 20% validate, 20% test\n",
    "    data_train, data_val, data_test =  = sample_data(date_start, date_end, data_split, n_observations)\n",
    "\n",
    "    # configurable function\n",
    "    objective_function = objective_LSTM(trial, data_train, data_val, data_test, forecast_horizon)\n",
    "\n",
    "    def safe_objective(trial):\n",
    "        try:\n",
    "            return objective_function\n",
    "        except Exception as e:\n",
    "            print(f\"Failed trial: {e}. Skipped this trial.\")\n",
    "            return float('inf')\n",
    "\n",
    "    # warnings.filterwarnings(\"ignore\")\n",
    "    study1 = optuna.create_study(direction='minimize')\n",
    "    study1.optimize(safe_objective, n_trials=trials)\n",
    "\n",
    "    trial = study1.best_trial\n",
    "\n",
    "    # warnings.filterwarnings(\"default\")\n",
    "\n",
    "    if trial.value != float('inf'):\n",
    "      save_tuning(config_name=f'{model_name}_{forecast_horizon}', trial)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
